{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# std library imports\n",
    "from datetime import datetime as Datetime\n",
    "import datetime\n",
    "# from copy import deepcopy\n",
    "# import html\n",
    "import json\n",
    "# from json import JSONDecodeError\n",
    "from pathlib import Path\n",
    "# import re  # regex\n",
    "import ssl\n",
    "# from socket import timeout\n",
    "# import sys\n",
    "from typing import List\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError, URLError\n",
    "\n",
    "\n",
    "# stuff needed for parsing and manipulating XML\n",
    "# this moduel does not come with python and needs to be installed with pip\n",
    "from lxml import etree  # type: ignore\n",
    "# from lxml.etree import QName, Element, SubElement, iselement  # type: ignore\n",
    "# from lxml import html as lhtml\n",
    "\n",
    "\n",
    "FILEEXTENSION = '.xml'\n",
    "\n",
    "BASE_URL = 'http://services.vnp.parliament.uk/voteitems'\n",
    "\n",
    "# xml namespaces used\n",
    "# AID = 'http://ns.adobe.com/AdobeInDesign/4.0/'\n",
    "# AID5 = 'http://ns.adobe.com/AdobeInDesign/5.0/'\n",
    "\n",
    "# NS_ADOBE = {'aid': AID, 'aid5': AID5}\n",
    "\n",
    "# ns2 = 'http://www.w3.org/2001/XMLSchema-instance'\n",
    "# ns1 = 'http://www.w3.org/2001/XMLSchema'\n",
    "\n",
    "# Text before the following should get the speaker style\n",
    "# chair_titles = ('SPEAKER', 'CHAIRMAN OF WAYS AND MEANS', 'SPEAKER ELECT')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "CONTEXT = ssl._create_unverified_context()\n",
    "def json_from_uri(uri: str, default=None, showerror=True):\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    request = urllib.request.Request(uri, headers=headers)\n",
    "    try:\n",
    "        response = urllib.request.urlopen(request, context=CONTEXT, timeout=30)\n",
    "        json_obj = json.load(response)\n",
    "    except (HTTPError, URLError, timeout, JSONDecodeError) as e:\n",
    "        if showerror:\n",
    "            warning(f'Error getting data from:\\n{uri}\\n{e}')\n",
    "        return default\n",
    "    else:\n",
    "        return json_obj"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_sitting_dates_in_range(from_date: Datetime, to_date: Datetime) -> List[Datetime]:\n",
    "    \"\"\"get return a list of sitting day\"\"\"\n",
    "    \n",
    "    # date\n",
    "    cal_api_url_template = 'http://service.calendar.parliament.uk/calendar/proceduraldates/commons/nextsittingdate.json?dateToCheck={}'\n",
    "\n",
    "    \n",
    "    # the calendar api gives you the next sitting day so we need to start form the day before\n",
    "    start_date = from_date - datetime.timedelta(days=1)\n",
    "    \n",
    "    current_date = start_date\n",
    "    dates = []\n",
    "    count = 0\n",
    "    while current_date < to_date:\n",
    "        current_date = start_date + datetime.timedelta(days=count)\n",
    "        dates.append(current_date)\n",
    "        count += 1\n",
    "    \n",
    "    sitting_dates = []\n",
    "    for date in dates:\n",
    "        \n",
    "        next_sitting_date_str = json_from_uri(cal_api_url_template.format(date.strftime('%Y-%m-%d')))\n",
    "        next_sitting_date = Datetime.strptime(next_sitting_date_str[:10], '%Y-%m-%d')\n",
    "        sitting_dates.append(next_sitting_date)\n",
    "    \n",
    "    return sitting_dates"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "sitting_dates = get_sitting_dates_in_range(Datetime(2019, 10, 14), Datetime(2019, 11, 14))\n",
    "sitting_dates = list(dict.fromkeys(sitting_dates))\n",
    "print(sitting_dates)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[datetime.datetime(2019, 10, 14, 0, 0), datetime.datetime(2019, 10, 15, 0, 0), datetime.datetime(2019, 10, 16, 0, 0), datetime.datetime(2019, 10, 17, 0, 0), datetime.datetime(2019, 10, 21, 0, 0), datetime.datetime(2019, 10, 22, 0, 0), datetime.datetime(2019, 10, 23, 0, 0), datetime.datetime(2019, 10, 24, 0, 0), datetime.datetime(2019, 10, 28, 0, 0), datetime.datetime(2019, 10, 29, 0, 0), datetime.datetime(2019, 10, 30, 0, 0), datetime.datetime(2019, 10, 31, 0, 0), datetime.datetime(2019, 11, 4, 0, 0), datetime.datetime(2019, 11, 5, 0, 0), datetime.datetime(2019, 12, 13, 0, 0)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Save a bunch of XML files for future use\n",
    "def save_xml_from_dates(dates: List[Datetime]):\n",
    "\n",
    "    for date in [datetime.datetime(2019, 10, 14, 0, 0), datetime.datetime(2019, 10, 15, 0, 0), datetime.datetime(2019, 10, 16, 0, 0), datetime.datetime(2019, 10, 17, 0, 0), datetime.datetime(2019, 10, 21, 0, 0), datetime.datetime(2019, 10, 22, 0, 0), datetime.datetime(2019, 10, 23, 0, 0), datetime.datetime(2019, 10, 24, 0, 0), datetime.datetime(2019, 10, 28, 0, 0), datetime.datetime(2019, 10, 29, 0, 0), datetime.datetime(2019, 10, 30, 0, 0), datetime.datetime(2019, 10, 31, 0, 0), datetime.datetime(2019, 11, 4, 0, 0), datetime.datetime(2019, 11, 5, 0, 0), datetime.datetime(2019, 12, 13, 0, 0)]:\n",
    "        url = f'{BASE_URL}/{date.strftime(\"%Y-%m-%d\")}.xml'\n",
    "        # parse and build up a tree for the input file\n",
    "        try:\n",
    "            print(url)\n",
    "            xml = urllib.request.urlopen(url, context=CONTEXT, timeout=30)\n",
    "        except URLError:\n",
    "            print('Can\\'t seem to get XML. Are you on a parliamentary computer?')\n",
    "            return\n",
    "        output_path = Path(f'datedJournalFragemnts/{date.strftime(\"%Y-%m-%d\")}.xml')\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(xml.read())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "save_xml_from_dates(sitting_dates)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "http://services.vnp.parliament.uk/voteitems/2019-10-14.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-15.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-16.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-17.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-21.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-22.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-23.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-24.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-28.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-29.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-30.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-10-31.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-11-04.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-11-05.xml\n",
      "http://services.vnp.parliament.uk/voteitems/2019-12-13.xml\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from create_journal import main\n",
    "main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[datetime.datetime(2019, 10, 14, 0, 0), datetime.datetime(2019, 10, 15, 0, 0), datetime.datetime(2019, 10, 16, 0, 0), datetime.datetime(2019, 10, 17, 0, 0), datetime.datetime(2019, 10, 21, 0, 0), datetime.datetime(2019, 10, 22, 0, 0), datetime.datetime(2019, 10, 23, 0, 0), datetime.datetime(2019, 10, 24, 0, 0), datetime.datetime(2019, 10, 28, 0, 0), datetime.datetime(2019, 10, 29, 0, 0), datetime.datetime(2019, 10, 30, 0, 0), datetime.datetime(2019, 10, 31, 0, 0), datetime.datetime(2019, 11, 4, 0, 0), datetime.datetime(2019, 11, 5, 0, 0), datetime.datetime(2019, 12, 13, 0, 0)]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "Error reading file '2019-10-14.xml': failed to load external entity \"2019-10-14.xml\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22100/2330011362.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcreate_journal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\wigzellj\\Projects\\github\\commons-journal\\create_journal.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'datedJournalFragemnts/{date.strftime(\"%Y-%m-%d\")}.xml'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0minput_root\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0metree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# LXML element object for the root\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mtemp_output_root\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'day'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnsmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNS_ADOBE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\etree.pyx\u001b[0m in \u001b[0;36mlxml.etree.parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocument\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocumentFromURL\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocFromFile\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._BaseParser._parseDocFromFile\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._ParserContext._handleParseResultDoc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleParseResult\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._raiseParseError\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Error reading file '2019-10-14.xml': failed to load external entity \"2019-10-14.xml\""
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('venv-cj': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "127fc95115e3fe18924af9e2cad3847cca318fae7ace227e965aac003d356fd9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}